 @Misc{covid19-kaggle-r,
    title = {Coronavirus COVID-19 (2019-nCoV) Epidemic Datasets},
    url = {https://www.kaggle.com/ds/574488},
    doi = {10.34740/KAGGLE/DS/574488},
    publisher = {Kaggle},
    author = {Emanuele Guidotti},
  }


@article{dong2020,
  title={An interactive web-based dashboard to track COVID-19 in real time},
  author={Dong, Ensheng and Du, Hongru and Gardner, Lauren},
  journal={The Lancet infectious diseases},
  year={2020},
  publisher={Elsevier}
}

@Manual{rcoronavirus2020,
    title = {coronavirus: The 2019 Novel Coronavirus COVID-19 (2019-nCoV) Dataset},
    author = {Rami Krispin},
    year = {2020},
    note = {R package version 0.1.0.9002},
    url = {https://github.com/covid19r/coronavirus},
  }



%How to cite item
%EpiModel: An R Package for Mathematical Modeling of Infectious Disease over Networks
%Citation Format  
@article{jeness2018-epimodel,
   author = {Samuel Jenness and Steven Goodreau and Martina Morris},
   title = {EpiModel: An R Package for Mathematical Modeling of Infectious Disease over Networks},
   journal = {Journal of Statistical Software, Articles},
   volume = {84},
   number = {8},
   year = {2018},
   keywords = {mathematical model; infectious disease; epidemiology; networks; R},
   abstract = {Package EpiModel provides tools for building, simulating, and analyzing mathematical models for the population dynamics of infectious disease transmission in R. Several classes of models are included, but the unique contribution of this software package is a general stochastic framework for modeling the spread of epidemics on networks. EpiModel integrates recent advances in statistical methods for network analysis (temporal exponential random graph models) that allow the epidemic modeling to be grounded in empirical data on contacts that can spread infection. This article provides an overview of both the modeling tools built into EpiModel, designed to facilitate learning for students new to modeling, and the application programming interface for extending package EpiModel, designed to facilitate the exploration of novel research questions for advanced modelers.},
   issn = {1548-7660},
   pages = {1--47},
   doi = {10.18637/jss.v084.i08},
   url = {https://www.jstatsoft.org/v084/i08}
}

@article{Agostinelli2011,
abstract = {Local depth is a generalization of ordinary depth able to reveal local features of the probability distribution. Liu's simplicial depth is primarily used, but results for Tukey's halfspace depth are also derived. It is shown that the maximizers of local depth can help to detect the mode(s) of a probability distribution. This work is devoted to the univariate case, but the main definitions are stated in the general multivariate case. Theoretical results and applications are illustrated with several examples. {\textcopyright} 2010 Elsevier B.V.},
annote = {This paper proposes 2 local depth that switches the definitions of the global depths they update in such a ways the the geometry changes are pretty clean.

Local depth definitions:
1. Local simplicial depth (t is tuning): 
ld{\_}s(x, t) = Proportion of simplicials of size p that contain x (p should be at least d + 1 - where d is size of space) *is the extension of this actually check the triangle inequality and see if the max distance is below tau?*

2. Local halfspace depth:
d{\_}hs: halfspace is converted into slabs. then same definition is applied

In 4.1 they have some examples but also discuss some quick ways one might tune tau (specifically using the distribution of |X{\_}1 - X{\_}2| (in 1d space)

- example (22) shows that - with too small a selection of tau, you gets a high number of patial maximum ("local") - think about how to avoid it?

- proposed examining |x{\_}1 - x{\_}2| distribution (For 1d) to select tau.
* could we provide analysis to how tau is "just right"? (min should probably be our $\backslash$delta

- also mentioned a way to test if a point is a mode (this is depend on tau {\&} it seems to have the reverse null hypothesis then as desired) - not sure this is need to be extended -but if there was a way to think about H{\_}t,n as a function of tau we might be able to better capture tau. 

- I don't think tau really needs to go to zero as n-{\textgreater} infinite. Does this match with KDEs?},
author = {Agostinelli, Claudio and Romanazzi, Mario},
doi = {10.1016/j.jspi.2010.08.001},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Data depth,Halfspace depth,Multimodal distribution,Simplicial depth},
month = {feb},
number = {2},
pages = {817--830},
publisher = {Elsevier B.V.},
title = {{Local depth}},
volume = {141},
year = {2011}
}

@misc{Geenens2017,
abstract = {The concept of depth has proved very important for multivariate and functional data analysis, as it essentially acts as a surrogate for the notion a ranking of observations which is absent in more than one dimension. Yet, naive attempts to extend to the functional context some succesful multivariate depth measures have been seen to lead to absurd results, as they failed to take into acount in their construction purely functional features such as continuity, smoothness and contiguity. In this paper we suggest a natural depth which satisfies all the properties that a valid functional depth measure should fulfill. It is explicitly constructed on a certain distance d between functional objects, which has to be selected by the analyst. This allows the depth measure to really be tailored to the data at hand and to the ultimate goal of the analysis, a very desirable property in functional data analysis given the polymorphic nature of those data. This flexibility is thoroughly illustrated by several real data analyses, including an original one pertaining to the field of Symbolic Data Analysis},
author = {Geenens, Gery and Nieto-Reyes, Alicia},
title = {{On the functional distance-based depth}},
year = {2017}
}